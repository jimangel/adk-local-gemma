# ==============================================================================
# LLM CONFIGURATION
# ==============================================================================
# Choose your LLM type: "cloud" (Gemini) or "local" (LM Studio)
LLM_TYPE=cloud

# ------------------------------------------------------------------------------
# CLOUD LLM Settings (Gemini)
# ------------------------------------------------------------------------------
# Used when LLM_TYPE=cloud
GOOGLE_GENAI_USE_VERTEXAI=FALSE
GOOGLE_API_KEY=YOUR_KEY_HERE

# Gemini model selection
# gemini-2.5-flash-lite
# gemini-2.5-flash
# gemini-2.5-pro
# https://ai.google.dev/gemini-api/docs/models
GEMINI_MODEL=gemini-2.5-pro

# ------------------------------------------------------------------------------
# LOCAL LLM Settings (LM Studio)
# ------------------------------------------------------------------------------
# Used when LLM_TYPE=local
# Make sure LM Studio is running with "Enable Server" checked
LM_STUDIO_API_BASE=http://127.0.0.1:1234/v1/
# Change this to a model that supports function calling:
# Model that supports function calling (gpt-oss-20b, qwen/qwen3-1.7b, qwen/qwen3-4b-2507)
LM_STUDIO_MODEL=qwen/qwen3-4b-2507

# ==============================================================================
# KUBERNETES CONFIGURATION
# ==============================================================================
# Set your kubeconfig path here (optional - will use this if set)
KUBECONFIG=your_kubeconfig_path_here