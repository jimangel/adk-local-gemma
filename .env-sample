# ==============================================================================
# LLM CONFIGURATION
# ==============================================================================
# Choose your LLM type: "cloud" (Gemini) or "local" (LM Studio)
LLM_TYPE=cloud

# ------------------------------------------------------------------------------
# CLOUD LLM Settings (Gemini)
# ------------------------------------------------------------------------------
# Used when LLM_TYPE=cloud
GOOGLE_GENAI_USE_VERTEXAI=FALSE
GOOGLE_API_KEY=YOUR_KEY_HERE

# Gemini model selection
# gemini-2.5-flash-lite
# gemini-2.5-flash
# gemini-2.5-pro
# https://ai.google.dev/gemini-api/docs/models
GEMINI_MODEL=gemini-2.5-pro

# ------------------------------------------------------------------------------
# LOCAL LLM Settings
# ------------------------------------------------------------------------------
# Used when LLM_TYPE=local
LM_STUDIO_API_BASE=http://localhost:11434/v1/           # for  Ollama
# LM_STUDIO_API_BASE=http://127.0.0.1:1234/v1/   # for LM Studio


# model selection
# LM_STUDIO_MODEL=qwen/qwen3-1.7b # for LM Studio
LM_STUDIO_MODEL=qwen3:1.7b # for Ollama

# ==============================================================================
# KUBERNETES CONFIGURATION
# ==============================================================================
# Set your kubeconfig path here (optional - will use this if set)
KUBECONFIG=your_kubeconfig_path_here